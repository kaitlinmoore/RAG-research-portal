# survey_ml_orbit2024 -- Machine Learning in Orbit Estimation: A Survey

**Authors:** Francisco Caldas, Cláudia Soares
**Venue:** Acta Astronautica, Vol. 220, pp. 97–107 (Elsevier) (2024)
**DOI:** https://doi.org/10.1016/j.actaastro.2024.03.072

---

## sec0 -- Abstract

[sec0_p1] Since the late 1950s, when the first artificial satellite was launched, the number of Resident Space Objects has steadily increased. It is estimated that around one million objects larger than one cm are currently orbiting the Earth, with only thirty thousand larger than ten cm being tracked. To avert a chain reaction of collisions, known as Kessler Syndrome, it is essential to accurately track and predict debris and satellites' orbits. Current approximate physics-based methods have errors in the order of kilometers for seven-day predictions, which is insufficient when considering space debris, typically with less than one meter. This failure is usually due to uncertainty around the state of the space object at the beginning of the trajectory, forecasting errors in environmental conditions such as atmospheric drag, and unknown characteristics such as the mass or geometry of the space object. Operators can enhance Orbit Prediction accuracy by deriving unmeasured objects' characteristics and improving non-conservative forces' effects by leveraging data-driven techniques, such as Machine Learning. In this survey, we provide an overview of the work in applying Machine Learning for Orbit Determination, Orbit Prediction, and atmospheric density modeling.

---

## sec1 -- Introduction

[sec1_p1] It is estimated that more than 36,000 objects larger than 10 centimeters and millions of smaller pieces exist in Earth's orbit [1]. To safeguard active spacecraft, it is necessary to accurately determine where each Resident Space Object (RSO) is and where it will be at all times. To create such a complex body of knowledge, the more broad problem of orbit estimation is divided into sub-problems, each largely complex but with more specific goals. In this review, we observe three main sub-problems: Orbit Determination, Orbit Prediction, and Thermospheric Mass Density.

[sec1_p2] Orbit Determination (OD): the OD is the determination of the orbit of the object based on observations [2,3]. The Extended Kalman Filter (EKF) [4–6] is the de facto standard for orbit determination in real-world scenarios [7]. The accuracy of this process depends on the number of sequential observations used to determine the orbit, and the type of observation, e.g., laser ranging and GPS tracking, which is far more precise than optical observations. The output of this method is commonly a state vector of the orbit of the object, usually represented through a vector consisting of the object's estimated position and velocity and a covariance matrix reflecting the uncertainty under the Gaussian assumption. Currently, this process is limited by the assumptions of the EKF, a lack of knowledge of RSO's shape and attitude, and dynamic model simplifications, which we will further examine in Section 3.

[sec1_p3] Orbit Prediction (OP): Orbit Prediction is the process of predicting the future position and associated uncertainty of any given RSO. Two method families exist for OP: one pursuing analytical solutions [8,9], with the other exploiting numerical approximations [10]. Numerical methods are time-consuming but precise, while analytical methodologies are more straightforward and faster. To be tractable, these algorithms hold simplifying assumptions that hinder accuracy [2]. Each method is limited by OD in that an orbital state with high uncertainty will necessarily evolve to have an inaccurate Orbit Prediction. When used in a Collision Avoidance scheme, this process propagates the state of the RSO until the time of closest approach (TCA) to any actively monitored satellite. The current limitations in Orbit Prediction are the Gaussian assumption – which does not hold against the true distribution [11] – the simplified modeling of perturbation forces, the unknown information regarding RSO characteristics, and the uncertainty over space weather forecast data (see Fig. 1).

[sec1_p4] Thermospheric Density Mass Models: A set of force models determine the acceleration of any RSO. Earth's gravity potential is the most meaningful, but solar and lunar gravitational attraction and Earth/ocean tides affect the RSO [8]. Of the non-conservative forces, air drag is the most relevant for objects in LEO. Being applied in the opposite direction of the RSO's velocity, this force is the largest source of uncertainty for most RSOs in LEO [12], and correctly determining atmospheric density is vital to compute satellite drag. All state-of-the-art models currently used for density estimation are empirical (data-driven) models that have been consistently updated since the last century. The lack of predictive capability and uncertainty estimation are the two main drawbacks of these methods.

[sec1_p5] [Table 1: Outlining of input and output for each task.] The input and output for each task are as follows: Orbit determination takes Ground station (GS) observations as input and produces Orbital states at time t0 as output. Orbit propagation takes Orbital states as input and produces Orbital states at time t1 as output. Thermospheric density takes Space weather (F10.7, ap, etc.) as input and produces Local density and temperature as output.

[sec1_p6] In the following sections, we will thoroughly review published work using machine learning techniques to help solve each of the problems mentioned previously. Each section will start with a brief description of the task, followed by a state-of-the-art review of the current classical methods. The machine learning body of work will be presented in semi-chronological order, from the initial use of historical data to improve physical models to the most recent developments in the area that use highly complex models. The following section will briefly define the physical forces that determine the orbit of a satellite or space debris.

---

## sec2 -- Forces model

[sec2_p1] The equation of motion of a space object in a Cartesian ECI (Earth-Centered Inertial) coordinate system [2,13] can be written in the form [Equation 1: equation of motion for a space object, with acceleration equal to the central gravitational term plus perturbing accelerations], where r = ||r|| is the norm of the position vector, [r r_dot]^T = x, and mu_Earth is the gravitational constant multiplied by the masses of the Earth and the RSO, with the perturbing forces being [Equation 2: perturbing accelerations decomposed as sum of non-spherical gravity, solar/lunar, drag, solar radiation pressure, tides, and other perturbations]. For a given initial condition x(t0) = x0, the position of a satellite at any point in time can be implicitly written as the solution of the equation flow phi: [Equation 3: state at time t as the flow solution phi(t; x0, t0)].

[sec2_p2] The perturbation of Earth's gravity potential, a_NS, is due to the fact that Earth is not a perfect sphere. This force is modeled using spherical harmonic potential equations, with varying levels of precision depending on the degree. The most recently published model, the Earth Gravity Model (EGM2012), has coefficients up to degree 2190 and is accurate to 0.1 m [14]. The n-body perturbations, a_S/M, affect the trajectories of RSOs in orbit, with the Solar and Lunar perturbations being the two most relevant forces on the space object's body [15]. Other planets in the solar system, such as Jupiter, have minimal impact on satellites.

[sec2_p3] The atmospheric drag, a_drag, especially in the Thermospheric layer (85/125–600/1000 km), has non-negligible effects, and it is responsible for the decay of orbits in Low Earth Orbit (LEO). Using the canon-ball model, the aerodynamic drag can be represented by [Equation 4: atmospheric drag acceleration as function of atmospheric density, drag coefficient, cross-sectional area, mass, and relative velocity squared] where rho is the local atmospheric mass density, c_D is the drag coefficient, A_ref is the cross-sectional area, m the mass of the space object, v_rel the magnitude of the relative velocity of the object with respect to the rotating atmosphere and v_hat_r the unit vector of the relative velocity. For most satellites, the mass and cross-sectional areas are known in advance and are assumed to be constant for the lifespan of the satellite, despite slight changes that might occur due to, for example, fuel consumption. However, this is not the case for most RSOs, especially space debris originating from breakups. Taking that into account, it is common to define a combined parameter, the Ballistic Coefficient (BC = m / (A_ref * c_D)), which integrates mass, area and drag coefficient to be calculated as an extra feature during Orbit Determination. The local mass density rho is the variable obtained from the Thermospheric Density Mass models, which is particularly challenging to model, as we will see in Section 5.

[sec2_p4] The Solar Radiation Pressure, a_SRP, is the force that arises from the absorption and reflection of light from the Sun. It depends on the cross-sectional area and mass, but unlike atmospheric drag, it does not depend on altitude, but on the Sun-space object distance. It is the dominant non-gravitational perturbation on higher altitudes (MEO and GEO) and for High Area to Mass Ratio (HAMR) objects [11]. Of particular importance to the representation of this force is the determination of the entry and exit times of a given RSO from the shadow of the Earth, along with the determination of the force orientation, as the object-Sun vector is constantly changing and, with it, the cross-sectional area.

[sec2_p5] Tidal effects, a_tides, are also taken into account in orbital determination, with the small periodic deformations of the solid body of the Earth referred to as solid Earth tides, which, alongside ocean tides, impact Earth's gravity potential [8]. Other perturbations include General Relativity theory adjustments, geomagnetic pulls, Earth's albedo, and atomic clock corrections.

---

## sec3 -- Orbit Determination

[sec3_p1] This is the process of using observations to obtain a state vector x in R^p of a given space object [18]. In this survey, space objects will be all objects, either satellites or space debris, currently orbiting the Earth. A state vector of p = 6 is sufficient to represent the velocity and position of the satellite at a given time. Still, other variables, such as the Ballistic Coefficient (BC) or clock bias, can also be calculated as part of the state vector [19]. This state vector can also be represented by the traditional Keplerian elements (e, a, i, Omega, omega, theta) or by equinoctial elements (a, h, k, p, q, l). The types of observations used for this purpose are radio, radar, laser, or image, with observations usually divided between cooperative or non-cooperative observations [17]. As the name suggests, cooperative observation is when the object in question, e.g., a satellite, has a built-in capability to respond to tracking. This gives the Ground Station (GS) the ability to know with detail the position and ID of the object. In this case, we have a significant amount of observations across the period in which the GS, or GS's, communicate with the satellite. The non-cooperative observations are necessary to track defunct satellites or space debris. In this case, identifying the satellite is a necessary part of the process, and the number of observations, usually radar, is relatively small for each space object.

[sec3_p2] The state-of-the-art approach for this problem is the Extended Kalman Filter (EKF) [2]. This method approximates the Kalman Filter to non-linear systems, such as the equations of motion of a space object [7]. Its limitations include using only the first-order Taylor series expansion to approximate the system to a linear system and the assumption that the measurement and process noise is Gaussian [20]. Despite that, the applicability of the filter for sequential data, alongside providing a probability distribution of the estimated state, proves very useful and justifies the current use. Because of the relevance of the EKF method to orbit determination, we will briefly explain the algorithm.

[sec3_p3] The intended goal of this method is to combine knowledge of the dynamical system with observations. Therefore the dynamical and observation equations can be represented as [Equations 5: dynamical equation as state derivative equal to system function plus process noise, and observation equation as measurement equal to measurement function plus measurement noise] where w(t) distributed as N(0, Q(t)) is the process noise, y_k is the measurement, h(x_k) the measurement function and v_k the measurement noise following a zero-mean Gaussian with covariance R_k, v_k distributed as N(0, R_k). Through this general formula, we can observe that the formula combines discrete observations with continuous dynamical equations. When f(x, t) and h(x_k) are linear functions, and the initial distribution is Gaussian, with w(t) and v_k expressing white noise (uncorrelated Gaussian distributions with zero-mean), the Kalman Filter is the optimal filter [22]. A known and much-studied filter in the automatic control and time-series research fields, many books [23–25] present in-depth explanations of the Kalman filter, which can be summarized as a two-step algorithm (predict and filter).

[sec3_p4] The Extended Kalman Filter is applied when the linearity assumption does not hold, particularly the linearity of f(x, t) and/or h(x_k). To do so, and before the KF algorithm in Fig. 2 ought to be used, both equations are linearized using the first order of Taylor's approximation at each observational moment k: [Equations 6: first-order Taylor series linearization of the dynamical function f and measurement function h around the current state estimate]. Note in Fig. 2 that the prediction step for the a priori mean (x_hat_k|k-1) does not need a linear function. It is the covariance matrix and the Kalman Gain matrix that require the simplification of the dynamical and measurement equations. This is precisely the intuition behind improvements over the base method such as the Unscented Kalman Filter (UKF) [5], the Second Order Kalman Filter [6], and others methods referred to in Lee [26]. These methods more closely represent the nonlinearity of the problem but are, nonetheless, Gaussian or linear approximations. Sequential Monte Carlo methods such as the Unscented Particle Filter [27] or the Divided Difference Particle Filter [26] are also popular and shown to be superior to the EKF by Arulampalam et al. [28] and Ning et al. [29], with the disadvantage of high computational costs [29]. The UKF, in particular, sits on the border between Monte Carlo and linear methods, with deterministically chosen sigma-points [5], made to represent the Gaussian distribution, being independently propagated across time through x_k+1 = phi(t_k+1; x_k, t_k) and then used to derive the mean and covariance at the k + 1 time step.

[Figure 1: The two main stages of orbital estimation necessary for collision avoidance and debris and satellite tracking. The information obtained from OD is used as input for Orbit Prediction (OP). Source: Figure adapted from [2,17].]

[Figure 2: General Kalman filter diagram. A_k is the state transition matrix at time k, K_k is the Kalman gain at each observational moment, H_k is the linear measurement mode at time step k, and the output is the estimated mean (x_hat_k) and covariance (Sigma_k) at time step k.]

[sec3_p5] More recently, the problem's non-linearity has been tackled through machine learning and data-driven techniques. Hartikainen et al. [30] used Latent Force Models (LFMs) to combine the dynamic system with a more freely defined measurement component, implementing Gaussian Processes (GP) to model measurement noise and using a machine learning approach to define the covariance structure of the Gaussian Process [31,32]. This method improves on the Kalman Filter by removing the uncorrelated white noise assumption and replacing it with a time-varying GP. A different method uses Physics Informed Neural Networks (PINN) to incorporate physical knowledge into the optimization process of the Neural Network [33]. This approach has been applied to the circular restricted three-body problem [34] and data from cislunar objects [35]. In Sharma and Cutler [36], it is presented a general approach to OD using distribution regression [37]. It is shown that under a known and continuous dynamic system, with known spacecraft characteristics and observable orbital parameters, there is a possible mapping from the probability distribution of the observed samples to the orbital parameters. This method can be used either to estimate the posterior distribution of the orbital parameters based on full batch observations or to identify the ID of the spacecraft associated with each sample. In [38], Sharma extends this work and presents a method for collaborative and non-collaborative orbit classification by estimating the probability of each sample to represent the distribution associated with its ID. This technique is particularly useful to identify satellites with identical Radio Frequency (RF) transmissions or very close orbits that were not extended to more than two spacecraft. The distribution regression approach was also followed in Jiang [39], extending the process to observations from more than one Ground Station (GS).

[sec3_p6] Different authors [13,40,41] independently presented an improvement over the current methods for OD by using Gaussian Mixture Models (GMMs) to model the estimated distribution. A Gaussian Mixture model is a mixture distribution created by combining multiple Gaussian distributions, as represented in [Equation 7: GMM probability density as weighted sum of k Gaussian components with means mu_i and covariances Sigma_i, where weights sum to one]. A GMM is known to approximate any other distribution given a sufficient number k [42,43], and therefore it is used to approximate the real distribution of the state during the OD period. This allows for a more accurate characterization of the distribution of X, being X the state at any given time during OD, while also being particularly useful for the step of Orbit Propagation (OP), as all current methods are capable of propagating a Gaussian distribution across time, and are trivially scalable to a finite number of independent Gaussian distributions. This work was extended by Vishwajeet et al. [44] and Terejanu et al. [45] by adapting the GMM weights across time, and further enhanced by Vittaldev [46,47] who presented a univariate splitting library along arbitrary directions that are used to generate a Multidirectional Gaussian Mixture Model. Horwood et al. [48] also proposed a new distribution to improve OD – the Gauss von Mises (GVM) distribution – using this distribution in tandem with a particular set of orbital elements, the J2 equinoctial orbital elements to reduce the non-linearity of the process. The GVM is the counterpart distribution of the Gaussian distribution for circular support. In a series of publications, Horwood et al. [11,49,50] compare their approach with the UKF, EKF, and GMM methods using a Particle Filter (PF) as the ground truth model. Both the GMM (k = 49) and the GVM are shown to faithfully represent the orbit distribution eight times longer than the UKF and the EKF (see Fig. 3).

[Figure 3: Uncertainty representation comparison between different filters for orbit determination. The blue marks are the ground truth representation using a PF. Image in Poore et al. [11]. In figure b), the green lines represent the distribution of the Extended Kalman Filter (EKF), the grey lines the Unscented Kalman Filter (UKF), and in yellow the Gauss Von Mises (GVM).]

---

## sec4 -- Orbit Prediction

[sec4_p1] Orbit Prediction can usually be seen as propagating a known orbital state to a future orbital state. The current physics-based methodology is to solve the differential equations of motion analytically or numerically to predict the mean state at a future time. The numerical methods are time-consuming, and the sheer number of space debris objects orbiting the Earth makes them only usable for academic or non-real-time applications [9,10]. In general, the non-linear stochastic dynamic system can be defined using the Ito stochastic differential equation (SDE) [3,51]: [Equation 8: Ito SDE with state derivative equal to deterministic dynamics plus diffusion term times Brownian motion] where f(x, t) is the deterministic part of the system, as seen in Eq. (1), G(t) is the diffusion of the process, and beta(t) is a Brownian motion, also known as a Wiener process, with zero mean and covariance Q. Given an initial probability distribution of x, p(x0, t0), the pdf at a future time p(x, t) is governed by the Fokker-Planck-Kolmogorov equation (FPKE) [52]: [Equation 9: FPKE governing the time evolution of the probability density function, with drift and diffusion terms] where nabla_x is the gradient in x viewed as a column operator. Solving this equation would provide a complete description of the position and uncertainty of the orbit at any time t > 0. However, there is no analytical solution to most FPKEs, with orbital mechanics being particularly hard to solve due to the nonlinearity of the perturbed dynamics in a state space with at least six dimensions.

[sec4_p2] The Orbit Prediction numerical approximations of this solution usually entail a set of assumptions to allow the problem to be solvable. In this review, before jumping to the advances in the field, we are going to present the more common approach for Orbit Prediction, where the output from the EKF, a Gaussian distribution with mean mu(t0) = mu0 and covariance Sigma0 is propagated according to a first-order system of SDEs. Using the SDE in (8), assuming the noiseless case (Q(t) = 0) and the flow solution (3), the mean and covariance at time t is: [Equations 10: propagated mean as flow solution of initial mean, and propagated covariance as State Transition Matrix times initial covariance times transpose of State Transition Matrix] where the flow solution phi(t; mu0, t0) and the State Transition Matrix (STT) Phi(t; mu0, t0) are solved by: [Equations 11: differential equations for the flow solution and the State Transition Matrix, with initial condition Phi(t0) = I] where Phi(t0; u0, t0) = I and, in the case of the EKF, the linearly propagated covariance is obtained with F(phi(t; mu0, t0), t) as the partial derivative of the function f(x, t) in Eq. (1): [Equation 12: Jacobian matrix F as partial derivative of dynamics f with respect to state x].

[sec4_p3] To solve the equations in (11) there are many numerical methods, with some numerical integration methods specialized for orbit propagation, as seen in Montenbruck and Gill [8] and Jones and Anderson [53]. The most relevant numerical integrators used for orbit propagation found in the literature include explicit Runge-Kutta methods such as Dormand-Prince 8(7) (DP8) or Runge-Kutta-Nystrom 12(10) (RKN12) and predictor-corrector methods, namely Adams-Bashforth-Moulton (ABM) and Gauss-Jackson (GJ) [11]. In particular, implicit Runge-Kutta methods such as the ones developed by Bradley et al. [54] (GL-IRK) and Bai and Junkins [55] (GC-IRK), are interesting algorithms for practical applications as they allow for parallelization, are A-stable [56] at all orders and are more accurate than DP8 [57]. To increase the stability and precision of these numerical methods, regularized orbital formulations, such as the Kustaanheimo-Stiefel (KS) [58,59] transformation, the Sperling-Buerdet regularization [60,61] and the DROMO [62,63] formulation were developed so as to reduce the impact of the non-linearity and singularities of the problem. Analytical methods are more common, and of those, the widely used method is the SGP4 (Simplified General Perturbations Model 4) [64]. Made available to the public in 2006 [15], it has since become a staple for Orbit Prediction, despite the lack of accuracy for long-time predictions and the non-inclusion of any information regarding uncertainty. The input data for SGP4 is a Two Line Element (TLE) set that includes information about the object and its orbit, such as satellite number, mean orbital elements, drag, ballistic coefficient, revolution number, and a time stamp. The fact that the information on Resident Space Objects is made publicly available through TLEs at space-track.org is one of the reasons for the ample use of SGP4 [65].

[Figure 4: Error sources in orbital prediction. Source: Adapted from Zhong Luo and Yang [17].]

[sec4_p4] Using the current methodology, two types of errors exist when making Orbit Propagation: satellite force model errors and measurement errors. The first error type relates to simplifications in the model, such as Earth's Gravitational harmonics model, or unknown information specific to the RSO, such as shape, attitude, or cross-sectional area. Measurement errors are all errors associated with the difference between the actual state of the satellite (such as position and velocity) and the measured state, including numerical truncation errors, as well as other navigation errors caused by clock accuracy or coordinate systems precision. In Fig. 4, we can see a summary of the error sources in Orbit Prediction, as presented by Zhong Luo and Yang [17] and Chen et al. [66].

[sec4_p5] In recent years, data-driven techniques have been used to tackle both sides of the problem, either employing machine learning to improve the model's representation of reality or mitigating the errors caused by numerical solutions and linear assumptions. Levit and Marshall [67] showed that when using a sufficient number of TLEs, they could be used as pseudo-observations to fit a high-precision special perturbations numerical propagator. This method was applied to a set of satellites, and the OP error was reduced from 1.5 km/day to 0.1 km/day. This work shows that past information can be leveraged to improve Orbit Prediction, which is a key factor for any Machine Learning setup. This work was closely followed by Bennett et al. [68], in which the same method was applied alongside a bias correction function.

[Figure 5: Illustration of the dataset structure for the ML approach to SGP4 error correction, as presented by Peng and Bai [71].]

[sec4_p6] Similarly, other authors [69,70] have shown improvement in the SGP4 prediction using error correction functions based on prediction error periodicity.

[sec4_p7] A second approach is to remove the physics-based propagator altogether. In Muldoon et al. [72], a data-driven model was proposed to approximate the SGP4 algorithm using a polynomial fit. A different method was introduced in Hartikainen et al. [30] using Latent Force Models (LFMs) to combine the physical models' principles with non-parametric data-driven components. This method allows determining future orbit positions and corresponding uncertainty by assuming Gaussian process (GP) priors on unknown forces. This work was extended by Rautalin et al. [73], who obtained favorable results for a set of satellite constellations in Medium Earth Orbit (MEO) and Geo-Synchronous Orbit (GEO).

[sec4_p8] Peng and Bai [74] have extensive publications in this field. In their first paper, a Support Vector Machine (SVM) is used to learn the historical error and improve the SGP4-based prediction within the error correction framework, as is presented in Fig. 5. In a simulated catalogue, they have shown that the error-correcting model can be deployed to improve RSO's Orbit Prediction. This duo of researchers also examined the capabilities of three ML models, specifically, Artificial Neural Networks (ANN), Gaussian Processes (GP), and Support Vector Machines (SVM) in [74–76], coming to the conclusion that the ANN had the best results, despite being more prone to overfitting. In Peng and Bai [71], the authors evaluated the SVM model on a real dataset and more recently proposed a data fusion approach to combine uncertainty information from the EKF OD process with the one obtained from the GP model [77].

[sec4_p9] This hybrid approach that uses an ML algorithm to correct the error in an orbit propagator, such as the SGP4, is the most common. Various neural network architectures have been leveraged for this purpose. Under the same hybrid SGP4 approach, four independent works show that Convolutional Neural Networks (CNN) [79], Feed-Forward Neural Networks (FNN) [80], Recurrent Neural Networks (RNN) [81], and Long-short Term Memory (LSTM) [82] can be used to improve SGP4 Orbit Prediction. Using a Gradient Boosting Decision Tree (GBDT) and a CNN, Li et al. [78,83] improved by more than 75% the along-track direction prediction for five satellites in LEO and GEO (see Fig. 6).

[Figure 6: Implementation flow of CNN in extracting patterns from the input. Neural network topology from Li et al. [78].]

[sec4_p10] All of this work has been done under the same data regimen, in particular using publicly available satellite data from the International Laser Ranging System (ILRS) as the ground truth and using a set of TLEs for a limited number of satellites as the training data. Two goals remain unaddressed in this research: the inclusion of exogenous variables in addition to TLE information and the generalization of machine learning models to unknown RSOs (referred to as type III generalization by Peng and Bai [84]). This would allow a single Machine Learning model to be used instead of creating a separate model for each RSO.

[sec4_p11] As mentioned before, two error sources exist in Orbit Prediction, and therefore two lines of work could be developed to enhance a physics-based model. The previously shown work focus is on correcting numerical errors and observational errors that occur when using simplifying assumptions, particularly the limited SGP4 propagator. A different approach is on using ML to improve our knowledge of the Earth, space, and RSOs, thus obtaining a more exact model of reality.

---

## sec5 -- Thermospheric Density Mass Models

[sec5_p1] Accurate prediction of the future state of Low Earth Orbit (LEO) objects requires knowledge of thermospheric mass density (the rho in (4)). Drag is known to be the main non-conservative force affecting satellites and debris in LEO [85].

[sec5_p2] The state-of-the-art models currently used are the Jacchia-Bowman 2008 (JB2008) [86], the Drag Temperature Model 2020 (DTM-20) [87], the Naval Research Laboratory for Mass Spectrometer and Incoherent Scatter radar 2.0 model (NRLMSIS 2.0) [88], and corrective models such as the High Accuracy Satellite Drag Model (HASDM) [12]. These models have a long history of improvement and refinement, dating back to the 1960s.

[sec5_p3] The MSIS series of models (MSIS-77 [89], MSIS-83 [90], MSIS-86 [91], MSIS-90 [92] and NRLMSISE-00 [93]) originally used mass spectrometer data and temperatures inferred from ground stations. Later, orbit-derived density and solar UV occultation measurements were incorporated.

[sec5_p4] The DTM series started in 1978 with the aptly named DTM-78 [94], using orbit-derived density data. Subsequent models (DTM-94 [95], DTM-03 [96], DTM-09 [97]) added accelerometer and mass spectrometer data, as well as temperature derived from incoherent scatter radar and optical airglow.

[sec5_p5] The Jacchia series of models began with Jacchia-60 [98]. It was followed by many iterations and derived models (J65 [99], J70 [100], J71 [101], MET-07 [102] and GRAM-99 [103]). More recently, the Jacchia-Bowman 2006 [104] was released, incorporating new solar indices.

[sec5_p6] For a more detailed look at the history of thermospheric density mass models and a comparison of recent models, we recommend the review by Emmert [85] and Chapter 8.6 in Vallado [2].

[sec5_p7] Empirical models use space weather indexes as input for forecasting and estimating local density, but the results are far from exact when used in Orbit Prediction [105]. On average, these models have a one-sigma accuracy of 10%–15%, depending on the model, solar activity, and location [106]. The data used in their configuration limits their predictive capacity, and forecast errors of the driving features can further compromise them. For example, a 10% error in Extreme Ultraviolet (EUV) light prediction can result in more than 200 km uncertainty for a given satellite after 7 days [107].

[sec5_p8] Since the 1990's, Machine Learning has been used to forecast space weather indexes, such as the F10.7, which is a proxy for EUV light. For example, an Artificial Neural Network (ANN) was used to predict solar flux [109], and Time delay Neural Networks (TDNN) were used to predict geomagnetic storms [110]. There is an abundance of scientific publications on this topic [111–115], and a comprehensive review is available in Camporeale's comprehensive survey [116].

[sec5_p9] To improve atmospheric mass density models, one approach is to use calibration data to fine-tune the parameters of the original model. This was the approach taken by Storz et al. [12] to develop the HASDM. Other authors have also achieved superior results with calibrated models: Doornbos et al. [117] used Two Line Element (TLE) data to calibrate a complex physical model, halving Orbit Prediction error. Shi et al. [118] used the same approach to calibrate the NRLMSISE-00 model during periods of increased solar activity. Sang et al. [119] suggested a process to calibrate any empirical model using the least squares method, which Chen et al. [120] found to be the most effective calibration method for reducing Orbit Prediction error. Combining multiple models can also reduce forecasting errors, as demonstrated when a Multi-model Ensemble [121], which combined three physical and empirical models was able to reduce forecasting error in the training and test sets. Perez and Bevilacqua [122] used a Neural Network to combine empirical models in order to reduce density error. Chen et al. [123] leveraged a Neural Network to calibrate models during magnetic storms, while Zhang et al. [108] and Gao et al. [124] used LSTM and Gaussian Processes, respectively, to calibrate the original models (see Fig. 7).

[Figure 7: The structure of the LSTM-NRL calibration model in Zhang et al. [108].]

[sec5_p10] Recently, a different approach has emerged, using Reduced Order Models (ROM) as a quasi-physical model. Mehta et al. [125] used a ROM to approximate the TIE-GCM complex physical model and simulated orbit ephemerides for model calibration. ROMs reduce the high-dimensional space to a lower dimension while preserving most information. This is usually done using Proper Orthogonal Decomposition (POD), also known as Principal Component Analysis (PCA), in the Machine Learning world.

[sec5_p11] This work was extended by using accelerometer-derived density estimates from the CHAMP and GOCE satellites [126], as well as TLE data [127]. Gondelach and Linares [128] showed that a ROM model with TLE-estimated densities provides more precise Orbit Determination than the NRLMSISE-00 and JB2008 models, particularly in the along-track coordinate. Turner et al. [129] improved this ROM approach by using an autoencoder for dimensionality reduction. Nateghi et al. [130] further refined it by using Sparse Identification of Nonlinear Dynamical systems (SINDy) to derive an explicit non-linear differential equation that defined the atmospheric density in the encoded (low-dimension) space, as presented in Fig. 8.

[Figure 8: Reduced Order Model (ROM) of thermospheric density conceptual representation. Where the prediction step is performed on a low dimension space and then the thermospheric density is reconstructed, as shown in Nateghi et al. [130].]

[sec5_p12] In 2017, Mehta et al. [131] published a global density estimate derived from the GRACE and CHAMP satellites using a physical model with high-fidelity drag coefficient modeling. This data was then used to develop an LSTM-based Neural Network for global density prediction, with promising results [132]. Bonasera et al. [133] used two Machine Learning techniques to derive uncertainty over the estimated density: Monte-Carlo Dropout and Deep Ensemble. Both techniques use sampling to obtain a probability distribution of the estimated quantity. Monte-Carlo Dropout "turns off" a percentage of the neurons in a Neural Network for each sample [43], while Deep Ensemble combines the output of a series of Neural Networks to obtain an estimated mean and uncertainty of the prediction [134] (see Fig. 8).

[sec5_p13] The same group of researchers also developed a method to forecast the input features for empirical models with uncertainty estimation, combining solar data images with time-series information [135]. In 2020, SET (Space Environment Technologies) made public 20 years of density data derived from HASDM, the model used by the United States Air Force [136]. This data was used to train a NN to replicate the HASDM model [137], using the same input, and to add uncertainty information through Monte-Carlo Dropout. Licata et al. [138] further advanced this work by using Bayesian Neural Networks on the global HASDM dataset and the local CHAMP dataset. Bayesian Neural Networks have recently gained more attention in the machine learning world, as they allow for a more principled understanding of uncertainty when compared to Monte-Carlo Dropout or Ensembles. They replace the neurons in a network, which are unknown parameters, or weights, with random variables, with the training process learning the probability distribution function of each neuron [139].

[Figure 9: Number of publications between 2000 and 2022 cited in this review, with applications divided by three categories: orbital determination, orbital prediction and atmospheric density mass models.]

---

## sec6 -- Future Challenges and Conclusion

[sec6_p1] In this section, we discuss some of the current and future lines of research in the field. We observe a shift from linear and physical models to more data-driven, non-linear models. Linear models were first used in the 1960s [4], but computational limitations have since been surpassed. The Gaussian assumption used in the Extended Kalman Filter (EKF) is now being questioned [11], and new approaches using Gaussian Mixture Models (GMM) [46], and the Gauss Von Mises (GVM) distribution [49] are promising. However, two main drawbacks remain: determining the exact number of Gaussian distributions necessary for accurate orbit determination and calculating the Probability of Collision (PoC). The GMM was evaluated for PoC using Monte Carlo simulation in Vittaldev [46], but this is too time-consuming for general use. Hall [140] generalized the PoC equation to any distribution and hypothesized the use of GMMs.

[sec6_p2] Most machine learning in this area is focused on density estimation, with limited use of Deep Learning techniques, with the exception of Chipade [141], who used an EKF-ANN hybrid. Many Deep Learning architectures have been used for Orbit Prediction, most of them with a focus on improving upon the SGP4 propagator. However, uncertainty in the ML-OP scheme is necessary for industrial use. Bayesian counterparts of Neural Networks, which predict a distribution, are being explored, such as Peng and Bai [77], who combined Gaussian Processes (GP) uncertainty with EKF-derived uncertainty, and Curzi et al. [81], who used a Deep Ensemble to perform variance estimation.

[sec6_p3] Research is also being done on estimating unknown physical properties of RSOs. For example, Guthrie et al. [142] used Siamese CNNs to estimate attitude, and Sharma and D'Amico [143] and Chen et al. [144] used CNNs combined with a 3D image generator to determine the pose of satellites. Linares et al. [145] leveraged deep learning techniques to determine RSOs shape using light curves data. Meta-Learning Models [146] are being explored to address the lack of labeled data.

[sec6_p4] Atmospheric density and air drag forces are considered in any current force model, but the current state-of-the-art models (e.g., JB2008, DTM) have 10 to 15% 1-sigma accuracy [105]. Recent papers [130,133,137] have proposed replacing these empirical models with modern deep learning models (see Fig. 9). Grey-box models, such as the one proposed by Nateghi et al. [130], are becoming more common since they are easier to evaluate and can implement physics-aware restrictions.

[sec6_p5] In conclusion, ML techniques can enhance and improve classical algorithms to help us better represent and understand the underlying physical phenomena. With the help of ML, predictions may become more focused on probability distributions rather than point-wise estimations, and the development of grey-box models – models that are simpler and more comprehensible to both space and ML specialists – can become increasingly important. This is the real challenge: how can ML be used to understand a system better, and in this case, the physical forces that govern space? In order to do this, we need to be able to combine the knowledge and expertise of both ML and space experts to create an environment that promotes collaboration and understanding. This can be achieved through the development of models which are mutually comprehensible and the introduction of ML-based tools that can help to bridge the gap between the two disciplines. Ultimately, this will help to create a more unified and practical approach to modeling physical processes.

[List of Acronyms omitted: notation and abbreviation definitions]
