# massimi2024 -- Deep Learning-Based Space Debris Detection for Space Situational Awareness: A Feasibility Study Applied to the Radar Processing

**Authors:** Federica Massimi, Pasquale Ferrara, Roberto Petrucci, Francesco Benedetto
**Venue:** IET Radar, Sonar & Navigation (2024)
**DOI:** https://doi.org/10.1049/rsn2.12547

---

## sec0 -- Abstract

[sec0_p1] The increasing number of space objects (SO), debris, and constellation of satellites in Low Earth Orbit poses a significant threat to the sustainability and safety of space operations, which must be carefully and efficiently addressed to avoid mutual collisions. The space situational awareness is currently addressed by an ensemble of radar and radio-telescopes that detect and track SO. However, a large part of space debris is composed of very small and tiny metallic objects, very difficult to detect. The authors demonstrate the benefits of using deep learning (DL) architectures for small space object detection by radar observations. TIRA radio telescope has been simulated to generate range-Doppler maps, then used as inputs for object detection exploiting You-Only-Look-Once (YOLO) frameworks. The results demonstrate that the object detection by using YOLO algorithms outperform conventional target detection approaches, thus indicating the potential benefits of using DL techniques for space surveillance applications.

---

## sec1 -- Introduction

[sec1_p1] Low Earth Orbit (LEO) is the most congested of all orbital regimes around Earth, owing to its proximity to our planet [1]. Typically defined as the area between altitudes of approximately 160 to 2000 km, LEO has witnessed a surge in the number of satellites being launched into space in recent years, with companies seeking to establish mega-constellations of communication satellites (as shown in Table 1) [2, 3]. These systems in fact can consist of tens of thousands of satellites [4].

[sec1_p2] [Table 1: Earth's orbits characteristics and occupancy.] Earth's orbits vary in characteristics and occupancy: LEO satellites orbit at heights of 700 to 1400 km with orbital periods of 10–40 minutes, hosting 4700 operating satellites and over 20,680 debris pieces; MEO satellites orbit at 10,000–15,000 km with periods of 2–8 hours, hosting 140 operating satellites and over 638 debris; GEO satellites orbit at 36,000 km with 24-hour periods, hosting 565 operating satellites and over 907 debris.

[sec1_p3] The popularity of LEO for mega-constellations can be attributed to its relatively low altitude, which enables the satellites to provide low-latency communication services. This makes them ideal for applications such as Internet access, remote sensing, and navigation. Moreover, the shorter signal path in LEO reduces the amount of power required to transmit signals to and from satellites, making them more cost-effective [5].

[sec1_p4] However, the increase in the number of satellites also heightens the possibility of satellite collisions, hence generating debris in orbit and, in turn, enhancing the possibility of further collisions. This phenomenon is like the growth of the asteroid belt. The accumulation of debris in this belt could surpass the natural flow of meteoroids, with implications for the design of future spacecraft [6]. There are over 12,000 trackable debris pieces in LEO, with most being 10 cm in diameter or larger. When including sizes down to 1 cm, there are about a million inferred debris pieces, all of which threaten satellites, spacecraft, and astronauts due to their orbits crisscrossing at high relative speeds. The population of debris includes both natural meteoroids and artificial orbital debris, such as any man-made object in orbit around the Earth that no longer serves a useful function (e.g. non-functioning spacecraft, abandoned launch vehicle stages, mission-related debris, and fragmentation debris). These objects are continually monitored, with over 27,000 detected so far (according to Space Surveillance Networks' estimate). Given that both debris and spacecraft travel at extremely high speeds (approximately 25,267 km/h), even the impact of a small debris fragment with a spacecraft could lead to significant problems [3].

[sec1_p5] Space situational awareness (SSA) is the capability to track, understand, and predict the behaviour of objects in space, including natural objects (e.g. asteroids) and man-made objects (e.g. satellites) and space debris. SSA is essential for ensuring safe and sustainable space operations, as it allows operators to monitor and avoid potential collisions, plan efficient trajectories, and maintain the functionality of space-based assets.

[sec1_p6] One of the most challenging tasks in SSA is the detection of small objects in space. This challenge is due to various factors, including the movement of objects in space, their relative speeds, and extreme distances. The difficulty increases due to the small size of the targets and the low resolution of the optical sensors, which can lead to problems such as occlusions, blurry backgrounds and changing lighting conditions.

[sec1_p7] The importance of these problems is emphasised in ref. [7], where an in-depth insight into the challenges of optical observation in space is provided. In optical observation based on space systems, three types of physical constraints mainly emerge: visibility condition, brightness condition and field of view (FOV) condition. The visibility condition is closely related to the visibility of objects in space. It is essential to ensure that objects of interest are visible and are not obstructed by other objects, such as the Earth, the atmosphere, or other satellites. Maintaining a continuous and uninterrupted line of sight to orbiting objects is essential for monitoring their movements. The brightness condition refers to the intensity of light emitted or reflected by objects in space. Different objects can have different brightness levels, [8]. This aspect is particularly critical for optical sensors and telescopes. For example, satellites can be highly reflective, appearing brighter than space debris or smaller objects. Dynamic range management and adaptation to brightness variations are key challenges for space observation systems. Finally, the FOV condition concerns the area observable by a sensor or observation system. The FOV determines which part of the sky or space can be monitored at any given time. It is essential that SSA systems have an adequate FOV to efficiently capture the region of interest. Additionally, the ability to adjust or adapt the FOV is important when observing different regions or objects in space.

[sec1_p8] The dynamic nature of space requires sophisticated survey instruments to assess collision risk and avoid damages to active satellites. The fast development of deep learning (DL) can bring numerous advantages in this field. For example, thanks to its ability to work with large amounts of data and to learn complex relationships from training data, DL could allow the detection of very small objects at very far distances. It also allows considerable flexibility and ability to adapt both to new types of targets and to a spatial environment subject to continuous physical changes.

[sec1_p9] The primary aim of this work is to present alternative and innovative methods for space debris detection using DL techniques. It specifically focuses on simulating a radar system to facilitate the comparison between traditional algorithms and the novel approaches based on DL.

[sec1_p10] The rest of this paper is organised as follows. In Section 2, we provide an overview of the space objects (SO) detection and tracking technologies employed in European radar and radio telescopes, as well as how DL can intervene to aid in the SSA problem. In Section 3, we recall both the basics of conventional and DL-based detection, by describing also how they are implemented in our study. Then, Section 4 illustrates the methodology we used to carry out the simulation, while Section 5 contains numerical results evaluated in scenarios affected by different types and levels of noise. Finally, Section 6 wraps up the paper by providing conclusions and future lines of research.

---

## sec2 -- Related Works

[sec2_p1] To mitigate the risks posed by space debris, it is essential to have accurate and up-to-date information on the location and trajectory of debris objects. The process involves monitoring and tracking the position and motion of space debris using various sensors and tracking systems such as optical telescopes, satellite-based sensors, and radars. With advancements in technology, DL techniques have been applied to SSA to improve the accuracy and efficiency of space debris tracking with radar.

### sec2.1 -- Space debris detection and tracking with radar and radio-telescopes

[sec2.1_p1] Radars play a crucial role in space debris detection and tracking. Radar systems are based on the simple echo principle: a signal is sent to a specific target, which reflects part of it, and the echo returns to the source. By bouncing radio waves off these objects and measuring the time it takes for the waves to return, radar systems can determine an object's distance, position, and velocity. This information is crucial for maintaining the safety and sustainability of space operations, as it allows operators to monitor and predict the behaviour of objects in space, including potential collisions [9].

[sec2.1_p2] There are several types of radar systems that can be used for space debris detection and tracking, including: 1. Phased Array Radar. This type of radar uses multiple antennas that can steer the beam in different directions without the need for any physical movement of the antenna itself. This allows for faster scanning of the sky and detection objects in multiple directions simultaneously. 2. Monostatic and Bistatic Radar. Monostatic radar uses a single antenna for both transmitting and receiving signals, while bistatic radar uses separate antennas. Bistatic radar can have better performance in terms of signal-to-noise ratio (SNR) and sensitivity, but it requires more hardware. 3. Multistatic radar involves multiple antennas for both transmitting and receiving signals. The antennas are distributed in different locations, creating a network of radar nodes that work together to detect and track targets. Multistatic radar offers enhanced coverage, increased system redundancy, and improved target detection capabilities. 4. Synthetic Aperture Radar (SAR) uses a large antenna or multiple antennas that can be combined to create a virtual antenna that is much larger than the physical antenna. This allows for higher resolution imaging of objects in space. SAR systems use flexible orbits, frequent data acquisition, and Doppler effect adjustments to target extremely manoeuvrable targets. Certain systems employ sophisticated methods like multi-pass interferometry and moving target tracking along with tracking devices to pursue these kinds of targets. Target comprehension is enhanced by integration with additional sensors, and real-time processing is essential for applications that call for quick judgements.

[sec2.1_p3] Regarding the European situation, an important system available 24/7 for surveillance observations is the Grand Réseau Adapté à la Veille Spatiale (GRAVES). It is a military continuous wave phased array bistatic radar operating at 143.05 MHz located in Dijon, France [10].

[sec2.1_p4] In ref. [11], the GESTRA (German Experimental Space Surveillance and Tracking Radar) radar system is a prime example of the use of phased-array radar technology in space surveillance and tracking. Developed by the Fraunhofer Institute (FHR), it is designed to detect and track objects in LEO at altitudes between 300 and 3000 km.

[sec2.1_p5] The Italian radar systems were proposed to be upgraded for space debris tracking in [12]. The aim of the article is to provide a detailed description of the BIRALES (BIstatic RAdar for LEo Survey) and BIstatic RAdar for LEo Tracking radar systems, which are part of the Italian contribution to the monitoring of space debris in LEO, including their hardware and software components.

[sec2.1_p6] The work [13] proposes EISCAT 3D, next-generation radar system currently under development, in Arctic Europe and designed for advanced measurement techniques. The system will consist of three sites located in northern Scandinavia, with each site consisting of around 10,000 antennas powered by a powerful 5 MW transmitter at Skibotn and a receiver at each of the three sites. The 3D EISCAT is designed to provide volumetric imaging, aperture synthesis and multistate imaging, tracking and adaptive experiments, along with continuous operations. This unique versatility will enable tracking of hard targets such as space debris, Near Earth Objects and meteor echoes in parallel with radar experiments to solve fundamental questions about layer coupling in the atmosphere, solar-Earth interactions, and plasma turbulence. An example of European SAR radar can be found in ref. [14].

[sec2.1_p7] COSMO-Sky Med is indeed a constellation of four SAR satellites: COSMO-Sky Med 1, 2, 3, and 4. Equipped with advanced SAR sensors, these satellites have the capability to capture high-resolution images of the Earth's surface under any weather conditions. By leveraging its SAR imaging capabilities, COSMO-Sky Med can capture images of space debris objects and track their movements over time. Furthermore, the high-resolution SAR imagery from COSMO-Sky Med assists in the identification and classification of space debris objects, aiding in the characterisation of the debris population. This information is crucial for understanding the distribution, density, and behaviour of space debris in orbit.

[sec2.1_p8] E-SAR [15] is an airborne SAR system that has been specifically designed for advanced remote sensing applications. It operates in various frequency bands, including X-band and P-band, allowing for flexible imaging modes and capabilities. The system is equipped with advanced imaging algorithms and processing techniques, enabling the acquisition of high-resolution SAR data over wide swaths. For space debris monitoring, E-SAR captures SAR images of the debris population, allowing researchers to track their trajectories and measure their characteristics and avoid collision.

[sec2.1_p9] An emerging trend for SSA is represented by spaceborn radar sensors (SBR) to complement ground-based surveillance. A comparison of the limits and the constraints of SBRs and ground-born radars is presented in ref. [16] by an ontological perspective. Recently, Maffei et al. in ref. [17] define the architecture of a monopulse-based pulse Doppler radar in Ka-band, equipped with an active electronically scanned array antenna, CFAR-like processing and Bayesian tracker for debris detection and tracking. The proof-of-concept has been extended to multiple-input-multiple-output (MIMO) in order to improve surveillance capability [18].

[sec2.1_p10] One of the main advantages of radar for space debris tracking is its ability to operate in all weather conditions and at all times of day. Unlike other components such as optical telescopes, which require clear skies and sunlight, radar can penetrate through clouds, dust, and debris, making it a valuable tool for monitoring the debris population. However, radar has some limitations, including its sensitivity to the size and shape of the object being tracked, its inability to distinguish between multiple objects that are close together, and the effects of plasma media with weak scintillation [19].

### sec2.2 -- Deep learning for SSA

[sec2.2_p1] DL algorithms can process huge amounts of data from sensors and tracking systems to detect and track SO, predict their future trajectories, and identify potential collision risks. DL has the potential to improve the accuracy and speed of space debris detection and tracking and could lead to more effective space traffic management strategies in the future. Furthermore, compared to conventional techniques, DL approaches often necessitate minimal or no pre-processing steps for training. As a result, these methods can automatically and efficiently extract features that may not be readily identifiable by humans [20].

[sec2.2_p2] Convolutional Neural Networks (CNNs) are commonly used in SSA because they excel in image recognition and object detection tasks, which are crucial in identifying and tracking SO. Convolutional Neural Networks are capable of learning complex features and patterns from large amounts of data, making them well-suited for analysing images captured by telescopes or radar systems [21]. In ref. [22], the authors present a novel approach using a fully convolutional network to detect the salience of space debris in a space surveillance platform. Unlike traditional methods that rely on costly optical flow calculations, this network learns the internal relationship between consecutive frames directly. However, the method may not be well-suited for detecting small targets as it has limited capability in extracting features from small space debris. In ref. [23], a data-driven classification approach is employed for the classification of SO using light curve data. The method uses CNNs to determine the shape class of a given SO based on its light curve observations. The shape classes considered in the study are rocket bodies, payloads, and debris. An advantage of the data-driven CNN approach is that it is simple to implement, as it does not require explicit data modelling. Research demonstrates that CNNs offer an accurate and computationally efficient method for classifying SOs based on their shapes [24]. The use of light curve data and the CNN architecture contribute to the high classification accuracy achieved in this study.

[sec2.2_p3] YOLO (You-Only-Look-Once) is a popular object detection algorithm that has been widely used in computer vision applications [25, 26]. Compared to other object detection algorithms, YOLO takes a different approach by dividing the input image into a grid and predicting the probability of objects in each cell of the grid, along with their bounding boxes and class labels. This means that YOLO only needs to make one pass across the image to detect objects, which leads to faster detection times than other algorithms that require multiple passes. The authors in ref. [27] highlight as small satellites can use computer vision and the YOLO v5 algorithm for real-time image classification and satellite component detection. The approach shows promising results and has the potential to contribute to autonomous capture of non-cooperative rolling target objects in space. By applying YOLO to radar data, SO can be detected and tracked with high accuracy and speed, even in cluttered environments with high object density.

[sec2.2_p4] Recently, Reinforcement learning (RL) has been explored in SSA [28, 29]. Reinforcement learning is a type of learning that allows an agent to learn through interactions with an environment, receiving rewards or punishments for actions taken. Reinforcement learning may be more appropriate when the optimal actions are not known in advance and the agent must explore the environment through trials and errors, learning better decisions in complex and dynamic environments, such as space. The aim of the authors in ref. [30] is to present a novel application of Double Deep Q Network (DDQN) to address a sensor management problem in the context of SSA. With the increasing number of satellites' launches into Earth's orbit, there is a pressing need to effectively manage a limited number of sensors to detect and track these objects. The authors propose the use of RL techniques to develop a sensor management policy for SSA. They create a simulation environment that emulates a controllable Earth-based telescope and train it using an extended Kalman filter to maximise the number of tracked satellites. By employing the DDQN policy, the authors show that the estimated state covariance matrices for observed satellites are significantly reduced compared to an alternate random policy.

[sec2.2_p5] The study [31] involves the training and testing of four Deep Reinforcement Learning (DRL) agents within a simulated environment of SSA. This environment is designed to accommodate several factors, such as sensor locations, objects in resident space, observation windows, and various sensor properties including action change and stabilisation time, dwell time, patterns measurement and process noises.

[sec2.2_p6] The research explores both fully connected neural network and CNN agents, evaluating their performance under different conditions, such as changes in orbital regimes, observation window lengths, observer positions, and sensor change. The study finds that DRL agents show robustness to most of these variations and consistently outperform short-sighted policies.

---

## sec3 -- Conventional Target Detection Strategies

### sec3.1 -- Classical approaches for target detection

[sec3.1_p1] The straightforward approach for detecting targets in range-Doppler maps is to apply a threshold to each cell of the map. By using the Neyman-Pearson criterion for hypothesis testing, the threshold can be set by fixing the probability of false alarm to a target value [32]. The threshold can be equal for each cell or adaptive with respect to the local background noise of the map. This second choice, also known as Constant False Alarm Rate (CFAR) detection [33], consists of adaptively setting the threshold for each cell in function of both the expected probability of false alarm and the noise statistics. This last is usually estimated in a neighbourhood of cells around the cell under test (CUT). Until today, CFAR represents the most used and effective criterion for target detection in radar signal processing [34]. Over the years, several variants have been proposed [35–37] aiming to mitigate the performance loss due to the finite number of training cells [38] or the presence of clutter that alters the noise distribution [39]. In this paper, we refer to three classical detector types:

#### sec3.1.1 -- Neyman-Pearson fixed-threshold detector

[sec3.1.1_p1] Target detection is accomplished for each CUT by means of a hypothesis testing between the null hypothesis H0 (noise only) and the alternative hypothesis H1 (signal plus noise): [Equation 1: Neyman-Pearson likelihood ratio test, comparing the ratio p(x|H1)/p(x|H0) against threshold τ to decide between H0 and H1]

[sec3.1.1_p2] Note that we set the threshold τ equal for each cell within a map and among different maps. We then vary the threshold value to produce Receiver Operating Characteristic (ROC) curves, by accounting for both true and false positives. A first advantage of using this method is its computational simplicity. Furthermore, it is not affected by any performance loss, such as in the case of CFAR-based methods, as well as it can detect targets in any range or Doppler frequency. Conversely, it is sensible to global and local variations of the noise statistics or system instability.

#### sec3.1.2 -- Cell-Averaging (CA) CFAR 1D

[sec3.1.2_p1] This approach estimates the mean noise power (Cell-Averaging configuration) in the leading and following range cells with respect to the CUT, for each Doppler filter in the map. Let Pr be the average noise power estimated from N neighbouring (a.k.a. reference) cells of the m-th range cell, then the threshold value is evaluated as follows: [Equation 2: CA-CFAR threshold as product of scaling factor α and estimated noise power Pr] where the subscript r is the range index. The parameter α is chosen in function of the desired probability of false alarm pfa. By assuming the I/Q noise samples as i.i.d. Gaussian distributed samples with a square-law detector, then: [Equation 3: CFAR scaling factor α as function of N reference cells and probability of false alarm pfa]

[sec3.1.2_p2] Because Pr is estimated from neighbour cells, CUTs close less than N/2 to the minimum and maximum range bins have less than N cells for the power estimate. Moreover, since Pr is a sample average that approximates the true power average, CFAR detector suffers of a performance loss compared to the fixed-threshold approach. Such a performance loss L is inversely proportional to the number of training cells: [Equation 4: CFAR performance loss in dB as negative log10 of pfa divided by N]

[sec3.1.2_p3] This behaviour will be taken into consideration in the design of the experiments to avoid undesired bias in the results.

#### sec3.1.3 -- Cell-Averaging (CA) CFAR 2D

[sec3.1.3_p1] It estimates the average noise power in a square neighbourhood of range and Doppler cells. Compared to the 1D version, the performance loss is negligible because of the larger number of training cells. Similar considerations about the CUTs close to the map edges (i.e. both in range and Doppler) apply for this method.

[sec3.1.3_p2] In our tests, we designed the CA-CFAR methods by assuming 32 training and 8 guard cells, (i.e. 16 and 4 respectively before and after the CUTs). The threshold factor α is set as in Equation (3). The theoretical probability of false alarm varies from 10−8 to 10−2.

### sec3.2 -- Clustering

[sec3.2_p1] The detection methods described above classify each CUT as occupied by a target or not. However, in realistic scenarios, a single target likely occupies more than one cell. This phenomenon is known as target spill-over. To address this issue, each detection scheme is followed by a clustering algorithm linking together close (in range and in Doppler) cells that are detected as containing a target. In our study, we define a clustering method based on graph theory. In particular, we construct an adjacency matrix Ai,j between all range-Doppler cells cr,d, whose subscripts (r, d) in [0, R − 1] × [0, D − 1] denote the coordinates along, respectively, the range and Doppler dimensions of a generic map with R × D cells. According to this notation, after the thresholding, ct_r,d = 1 whether a target is detected, 0 otherwise. Let us now define the generic subscript i (or j) as the C-ordered linearised version of the (r, d) coordinates, that is, i = d · R + r for all (r, d), identifying each cell in a map. Note that the adjacency matrix Ai,j is a binary matrix with (R × D) × (R × D) entries, populated as follows: for all i ≠ j and ct_i = ct_j = 1, then Ai,j = 1 if the following conditions are met simultaneously: (a) (‖i − j‖₁ mod(R − 1)) ≤ 1, that is, the 2 cells are close to each other in range; (b) (‖⌊i/R⌋ − ⌊j/R⌋‖₁ mod(D − 1)) ≤ 1, that is, the 2 cells are close to each other in Doppler.

[sec3.2_p2] The modulo operation in both conditions allows to deal with range and Doppler ambiguities, while ⌊*⌋ is the floor operator.

[sec3.2_p3] Once Ai,j is defined, clusters of cells γk are identified by finding the connected components of the undirected graph defined by Ai,j [40]. Finally, the range and Doppler of the target identified by the cluster γk are estimated as follows: [Equation 5: Target position estimate as argmax of cell values cr,d within cluster γk]

### sec3.3 -- YOLO-based detectors

[sec3.3_p1] YOLO (You Only Look Once) is an object detection algorithm that was first introduced by Joseph Redmon et al. in 2016. The key idea behind YOLO is to use a single neural network to predict both the class probabilities and bounding box coordinates of objects in an image. In contrast to traditional object detection algorithms that rely on multiple stages to detect objects, YOLO takes a different approach by processing the entire image in a single step. This design choice makes YOLO faster and more efficient compared to its counterparts. One important concept employed by YOLO is the use of anchor boxes. These anchor boxes serve as reference bounding boxes with predefined sizes and aspect ratios. By incorporating anchor boxes, YOLO improves its ability to accurately detect objects with different sizes and aspect ratios within an image.

[sec3.3_p2_1] The YOLO object detection algorithm operates through the following stages: 1. Input Image: The algorithm takes an image as input. This image can be anything from a photo to a frame inside a video. 2. Grid Division: The image is divided into a grid of cells, with each cell responsible for detecting objects within it. The grid size depends on the input image size and the network's final convolutional feature map size. 3. Feature Extraction: Each grid cell passes through a pre-trained CNN. This network learns relevant features from a large dataset to aid in object detection. These characteristics can include contours, textures and colours. 4. Object-ness Score: Each cell has a score called "object-ness score" to indicate whether there is an object in the cell. This prediction is based on a logistic regression function that calculates the probability of the presence of an object.

[sec3.3_p2_2] 5. Class Probability: If a cell predicts the presence of an object, it also assigns a class to the object with its probability. A SoftMax function calculates the conditional probability of the object for each possible class. 6. Bounding Box: For cells predicting objects, YOLO also predicts the bounding box enclosing the object. The 'bounding boxes' in the YOLO algorithm play a fundamental role in identifying and localising objects within an image. These rectangles provide valuable details about the location and size of each detected object. Centre coordinates (X, Y) indicate the approximate location of the object's centre within the grid cell. In other words, these values represent where the model assumes the centre of the object is relative to the cell edges. This representation is useful when the object is not perfectly aligned with the grid, as it allows to capture the movement of the centre relative to the centre of the cell. Width (W) and height (H) reflect the dimensions of the rectangle surrounding the object. These values are relative to the size of the grid cell. In other words, if an object occupies a significant part of the cell, the dimensions of the 'bounding box' will be larger; if the object is smaller, the dimensions will be smaller. This flexibility allows the 'bounding boxes' to adapt to changes in the size of objects in the image.

[sec3.3_p2_3] 7. Non-maximum suppression (NMS): YOLO applies NMS to eliminate redundant bounding boxes and improve detection accuracy. NMS removes overlapping bounding boxes with lower confidence scores, retaining only the most confident ones. 8. Output: The final result of the YOLO algorithm is a collection of "bounding boxes," each associated with a class and a confidence score. The confidence score is an indicator of how confident the model is that the object belongs to the predicted class. Usually, this score is represented as a probability value, and a higher score indicates greater certainty. This is critical to determining how much you can trust the object detection in that specific "bounding box." Essentially, a high confidence score suggests that the model is very confident that the object is present within the "bounding box".

[sec3.3_p3] To train YOLO networks, an advanced loss function has been defined in ref. [41] by considering three main aspects: Object confidence, which measures how well the model predicts the presence of an object in the grid cell; Background confidence, which measures how accurately the model predicts the absence of an object in the grid cell; and Intersection over Union, which describes the amount of overlap of the expected bounding box with the actual object's bounding box. This term helps in penalising inaccurate forecasts. The overall loss function is a weighted sum of these three metrics calculated over all cells and scales of the grid.

[sec3.3_p4] Since its introduction, YOLO has undergone several iterations, with each version building upon the previous one to enhance speed, accuracy, and functionality. Researchers and developers continue to refine and optimise the YOLO algorithm, resulting in improved performance for real-time object detection tasks [42, 43].

[sec3.3_p5] YOLO v5 brings significant improvements in terms of speed and accuracy compared to its predecessors. These advancements make it an exceptional algorithm for real-time object detection tasks. It is composed by backbone, neck and head. In this study, we employed the small version of the network (denoted as v5s in the literature), which consists of 7.2 million parameters and a computational efficiency of 16.5 GFLOPs.

[sec3.3_p6] The YOLO v5 backbone network extracts feature information from input images using the multiple CBS (Convolution + Batch normalisation + Sigmoid linear unit activation) stack, C3 (i.e. triple convolution) module, and the Spatial Pyramid Pooling Fusion (SPPF) module. The C3 module reduces computation and improves inference speed by learning residual characteristics across multiple bottleneck modules. The SPPF module merges multiscale information from feature maps, improving model accuracy. This is achieved with a 5 × 5 pooling kernel, reducing computational complexity and improving speed over the older SPP module used in previous versions of YOLO.

[sec3.3_p7] The neck network of YOLO v5 consists of a characteristic feature pyramid network and a path aggregation network (PAN). FPN propagates semantic information using a top-down approach, while PAN facilitates the propagation of low-level information for better localisation using a bottom-up approach. The neck network aggregates feature maps of different sizes to enhance semantic information and location characteristics, improving object detection for objects of various sizes.

[sec3.3_p8] The most important feature in these types of networks is maintaining the morphological properties of the patches. This is a crucial aspect to ensure that the model can make precise predictions about the contours and shapes of objects. Using multiscale feature maps (called P3, P4 and P5) from different parts of the backbone helps to maintain detailed information at different spatial resolutions, improving the model's ability to effectively detect small, medium, and large objects. In the process of building the "head" of the model, upsampling operations are performed on the feature map associated with P4 and P3 to increase the resolution of the feature map. Subsequently, these feature maps are concatenated with the corresponding feature maps from the backbone to combine information at different spatial scales. After upsampling and concatenation, the combined feature maps pass through the C3 modules. These modules are designed to refine the specific characteristics of objects at different scales. This workflow is repeated for the feature maps associated with P4 and P5, but with specific considerations for object sizes, such as small, medium, and large [42, 43]. Finally, the feature maps of P3, P4, and P5 are used to locate objects. The anchors associated with each scale are used to make predictions about object classes, confidence scores and bounding box coordinates. Anchors are predefined regions of interest with specific sizes and locations relative to feature maps. These anchors help the model generate bounding box proposals for objects in the image.

[sec3.3_p9] YOLO v8 is an advanced version of the previous versions of YOLO, with new features and improvements. Firstly, YOLO v8 boasts greater accuracy and speed than its predecessors. This means it can detect objects with greater accuracy while retaining real-time processing capabilities. The YOLO v8 implementation that we used in this study is the nano version (denoted as v8n in the literature), which has 225 layers, 3,157,200 parameters and a computational efficiency of 8.9 GFLOPs.

[sec3.3_p10] To capture high-level functionality effectively, YOLO v8 introduces an updated backbone network inspired by EfficientNet. This allows the model to understand complex visual patterns and make more accurate predictions.

[sec3.3_p11] Another addition in YOLO v8 is the new feature fusion module. This module combines capabilities of different scales, allowing the model to detect objects of various sizes and improve location accuracy. To further enhance its performance, YOLO v8 incorporates advanced data augmentation techniques such as MixUp and CutMix. These techniques augment training data by combining multiple images or mixing patches of images, leading to better generalisation and robustness [43].

[sec3.3_p12] The backbone extracts low- and high-level information through a combination of convolutional layers and C2f modules. The C2f module is an improved version of the original C3 module and acts as the primary residual learning module. This in fact reduces a standard convolutional layer in a way that not only preserves the lightness characteristics, but also captures more information about the gradient flow. The SPPF module allows creating a spatial pyramid abstraction. These extracted features are then used by the "head" of the model to generate predictions. As for YOLO v5, upsampling operations are performed on the feature maps associated with P4 and P3 to increase the resolution of those maps. These feature maps are subsequently concatenated with the corresponding feature maps from the model backbone. After concatenation, the combined feature maps (P3, P4 and P5) pass through C2f modules designed to refine specific features of objects at different scales.

[sec3.3_p13] To wrap-up this section, we make some global considerations about conventional versus DL-based detectors. Conventional approaches are, in some way, value-based detectors: in fact, the decision is made by comparing the value of a given CUT with respect to a threshold. In the case of CFAR, the threshold depends on both the expected probability of alarm and, overall, of a local statistics (first order, in the case of cell averaging) of the signal. Once the threshold is set, the decision is made by comparing only that specific value of the CUT with the threshold. Conversely, YOLO-based detectors exploit not only the values of the CUT (or single pixel, using a computer vision terminology), but also the morphology of the signal in the neighbouring cells. This feature, obtained thanks to the use of several convolutional filters at different scales, is expected to reduce the number of false detections, since now detection is not based on a single value which might be heavily affected by the noise. Moreover, the use of object and background confidence within the loss function allows the architecture to learn non-linear models of both the range-Doppler map background noise and the signal. For this last, the presence of target spill-over should not represent a critical issue as for classical approaches, because YOLO works at patch level rather than a cell level.

---

## sec4 -- Proposed Methodology

[sec4_p1] In this Section, we describe the baseline that we adopt to demonstrate the feasibility of using DL techniques in the SSA domain. A simplified block scheme of the data generation and processing is shown in Figure 1.

[Figure 1: Simplified block diagram of a generic pulse-doppler radar system and consequent digital processing, with the introduction of YOLO-based moving target detector after the matched filter.]

### sec4.1 -- Radar simulation

[sec4.1_p1] In our simulated environment, we model a ground-based radar that detects the presence of small objects (i.e. targets) in LEO orbit positions between a range of 300-2000 Km. The targets are assumed to be metallic spherical objects characterised by their own ranges, velocities, and Radar Cross-Sections (RCS). Without loss of generality, we carried out our experiments with objects whose diameters is comprised between half and 8 cm. The corresponding RCS are listed in Table 2, and are obtained by Mie series approximation [44, 45] as follows: [Equation 6: Mie series approximation for radar cross-section σrcs as a function of object radius r and wavelength λ, using spherical Bessel functions Jn and Hankel functions Hn] where r is the radius, k = 2π/λ, λ is the wavelength, Jn is the spherical Bessel function of the first kind of order n and Hn(1) is the Hankel function of order n.

[sec4.1_p2] [Table 2: Radar cross-section as the diameter of the spherical object varies.] Radar cross-sections for spherical metallic objects vary with diameter as follows: 0.5 cm diameter corresponds to an RCS of 0.000078 m², 1 cm to 0.000314 m², 2 cm to 0.001256 m², 4 cm to 0.005026 m², and 8 cm to 0.020106 m². Values are obtained by Mie series approximation.

[sec4.1_p3] As radar system, we target TIRA (Tracking and Imaging Radar), a prominent radar system in Europe, situated in Wachtberg, Germany. It operates in two frequency bands: L-band and Ku-band, enabling narrowband tracking and high-resolution imaging capabilities, respectively. The L-band transmitter emits high-frequency pulses with peak power ranging from 1 to 2 MW, utilising right-handed circular polarisation. As a monostatic radar, TIRA exhibits the capability to detect objects as small as 2 cm within a range of 1000 Km. Comprised of three main subsystems, the TIRA Radar delivers remarkable functionalities. Firstly, it features a 34 m satellite dish mounted on a computer-controlled azimuth-elevation mount, allowing for precise positioning of the radar antenna. The second subsystem encompasses a high-power 4-horn monopulse L-band tracking radar. Operating at the L-band frequency of 1.33 GHz, this radar utilises monopulse technology to achieve accurate target tracking. The third subsystem entails a broadband Ku-band imaging radar. Operating at a frequency of 16.7 GHz, this radar generates high-resolution Inverse Synthetic Aperture Radar images. With a maximum resolution of 6.3 cm, it facilitates detailed imaging of targets. The radar's narrow beamwidth of 3 dB (0.031°) enhances its precision in capturing accurate imaging data. To meet the demanding tracking requirements of SO, which often exhibit high velocities (approximately 8 km/s) in LEO, the TIRA antenna drive system is specifically designed. With a substantial mobile mass of around 240 tons, this drive system enables fast and agile movements. It can achieve a maximum angular velocity of 24°/s in azimuth and 6°/s in elevation, along with a maximum angular acceleration of 6°/s² in azimuth and 1.5°/s² in elevation. These dynamic capabilities ensure that targets are effectively tracked without any loss of tracking during their rapid movements in both the azimuth and elevation directions [46, 47].

[sec4.1_p4] Because TIRA in tracking mode is essentially a monostatic pulse radar system, we recall some basics about moving target detection processing in pulse-Doppler radar. At the receiver, the electromagnetic reflections caused by a target are split into their analogic in-phase (I) and quadrature (Q) components by means of coherent demodulation. Once the digital sampling is performed, the signal processing unit separates the reflected signal into a set of filters for each ambiguous range. The maximum unambiguous range is related to the inverse of the pulse repetition frequency (PRF). Then, the I and Q digital samples are organised into a matrix of time domain samples; columns correspond to range samples (fast time), while rows correspond to pulse intervals (slow time). Convolved with the matched filter by means of a Fast Fourier Transform, the output matrix provides a power spectral density estimate of the returned signal in function of the range and Doppler frequency. This matrix is also known as range-Doppler [33], and it contains information about the targets' presence, their positions and velocities.

### sec4.2 -- Datasets construction

[sec4.2_p1] To carry out our experiments, we have built proper datasets that have been structured as follows: the range-Doppler maps, created by using MATLAB, are transformed into a three-channel-like images by replicating three times the range-Doppler maps in logarithmic scale. This conversion involves scaling the values within the range of 0–255 to ensure compatibility with the YOLO v5 and v8 models. The range-Doppler maps are generated according to the system specification in Table 3: given a sample frequency of 5 kHz, a PRF = 25 Hz and 100 pulses, the maps are composed of 200 × 100 range-Doppler. It is worth noting that the number of pulses and the sample rate are not publicly available, so they are assumed in such a way to produce coherent results. The datasets are composed as follows:

[sec4.2_p2] [Table 3: Summary of TIRA tracking mode parameters.] The TIRA tracking mode parameters used in simulation are: propagation at light speed, 100 integrated pulses (assumed), 5 kHz sample rate (assumed), maximum range of 3000 km, operating frequency of 1.33 GHz (L-band), peak power of 1.5 × 10⁶ (linear), antenna gain of 49.7 dB, pulse width of 1 millisecond with rectangular pulse shape, PRF of 25 Hz, and antenna frequency range of 1–2 GHz.

[sec4.2_p3] I. The training set for YOLO architectures includes 3000 maps: 1000 maps with 1 target, 1000 maps with 2 targets and 1000 maps with 3 targets. These targets exhibit varying speeds and ranges between 300 and 2000 km, corresponding to LEO. Additionally, they possess RCS randomly selected from the values shown in Table 2. To account for background, 1000 additional maps with 0 targets were included in the training dataset. The noise figure was set to 0 dB.

[sec4.2_p4] II. The validation set, employed for the validation process of YOLO, includes 600 maps: 200 maps with 1 target, 200 maps with 2 targets and 200 maps with 3 targets. These targets have variable speeds, ranges between 300 and 2000 km, and variable RCS (see again Table 2). The noise figure was set to 0 dB, that is, no thermal noise is assumed at the receiver.

[sec4.2_p5] III. The test set consists of 1000 maps with only one target for each RCS values. The total number of maps to be tested is therefore 5,000, and they are used for computing performance metrics. Moreover, in order to make a fair comparison between the methods, we add a constraint about target velocity and range position to avoid that the targets occupy the training and guard cells of the CFAR-based methods, which could not be detected because of the loss expressed in (4). In this last set, the noise figure is set to 2 dB, which implies a loss of the SNR due to the thermal noise of the receiver, that we consider as additive white Gaussian noise (AWGN).

[sec4.2_p6] IV. Three additional datasets are created to consider disturbances other than AWGN. The datasets are generated by introducing pink noise with different power levels. The pink noise power, which decreases according to the law 1/|f|, is expressed as its difference, in dB, with respect to AWGN ground noise of the receiver. The levels Npink are 10 dB, 20 and 30 dB higher than the ground noise. The number of samples and the generation of the maps for training, validation and testing is the same as in I, II and III. Samples of maps are reported in Figure 2.

[Figure 2: Examples of tested range-doppler maps in case of additive white Gaussian noise (a), pink noise at 10 dB (b), at 20 dB (c) and at 30 dB (d), where a target with diameter of 4 cm is present approximately at the 75th range bin and at the 35th Doppler bin.]

[sec4.2_p7] The training and validation sets are used to retrain both the YOLO architectures from scratch. For both v8 and v5 models, the number of training samples that were used in each iteration step (batch size) was 32. Models were also trained with 100 epochs and Adam as the optimiser. As an illustrative example, we report in Figure 3 the training outcome of YOLO v5 in terms of box and object losses.

[Figure 3: Learning curves of YOLO v5. Upper plot shows the box losses for the training and validation sets. The lower graph illustrates the object losses.]

---

## sec5 -- Results and Discussion

[sec5_p1] In this section, we show the results obtained in our simulated environment. First, we define the metrics for measuring methods performance and we show the results when only AWGN is present at the receiver. Then, we generalise our tests to the presence of coloured noise.

### sec5.1 -- Performance metrics

[sec5.1_p1] The performance metrics that we used are the true positive rate (TPR) and the false positive rate (FPR). The TPR measures the ability of the algorithm to correctly identify and detect true targets. It is defined as the ratio between the number of true targets successfully detected by the system (NTP) over the total number of actual targets in the test set (Ntargets). In formula: [Equation 7: True positive rate TPR defined as NTP divided by Ntargets]

[sec5.1_p2] A higher probability of detection indicates a more effective algorithm in correctly identifying and detecting targets. The FPR is defined as the ratio between the number of false detected targets NFP over the total number of tested cells NCUTs in the experiment. In formula: [Equation 8: False positive rate FPR defined as NFP divided by NCUTs]

[sec5.1_p3] It is worth to note that, for the conventional approaches, NTP and NFP are the number of (true and false) targets detected after the clustering process introduced in Subsection 3.2. Each detected target is classified as a true positive if the differences between its range-Doppler position estimated as in Equation (5) and the truth position is less than a given tolerance that we set to 3. If more detections are in this acceptance region, only one target is considered as a true positive and the others are considered false positives. The targets detected outside the acceptance region are classified as false positives. For YOLO-based detectors, the clustering process is already embedded in the network architecture.

[sec5.1_p4] Finally, to visualise all performance in a single graph, we produce receiver operating characteristics (ROC) curves by expressing TPR in function of FPR by varying: the detection threshold τ of the fixed-threshold method; the (expected) probability of false alarm (PFA) of CFAR approaches from 10−8 to 10−2; and the output confidence level of the YOLO-based detector in the set {0.001; 0.25; 0.50; 0.75; 0.90}. For a better visualisation, the FPR scale is set to the logarithmic scale, such as in Figure 4.

[Figure 4: ROC curves of the detectors on additive white Gaussian noise for conventional and YOLO-based detectors.]

### sec5.2 -- Results on additive white Gaussian noise

[sec5.2_p1] The comparisons of the performance are illustrated in Figure 4. Some general comments about the results are needed to interpret the results. The cell averaging CFAR methods present a FPR considerably higher than the expected PFA. In theory, the FPR must converge to the PFA as the number of tests goes to infinity. Conversely, for example, in the case of one-dimensional CA CFAR, we observe a FPR ≅ 9·10−5 when the PFA is set to 10−8. This behaviour is explained by considering that the FPR is calculated over maps that contain one target. Because the presence of the target alters the local power statistics within a given map, it is not uncommon that some false detection appears because of, for instance, target spillover-effects or signal autocorrelation. Readers can refer to Figure 5, first column, for some examples.

[Figure 5: ROC curves on additive white Gaussian noise and pink noise before and after (dot lines with star marker) the training on noise maps.]

[sec5.2_p2] It is also worth to note that the TPR and the FPR are calculated in function of the number of true or false targets detected by each system. This means that for classical detectors these quantities are evaluated after having clustered the cells detected as potentially containing a target. Thus, it is not surprising that some non-linear effects might rise, such as the decrease of FPR when the PFA increases, because many cells (as expected with high PFA) might tend to be grouped in few clusters.

[sec5.2_p3] Figure 4 outlines as the CA CFAR-based methods and the Neyman-Pearson detector have similar performance in AWGN in the region with FPR > 10−4, while below this value we appreciate the loss in detection of CA CFAR 1D caused by Equation (4). Such a loss is negligible for CA CFAR 2D because it uses a higher number of reference cells, that is, 32 in range and Doppler. On the other hand, YOLO-based methods provide a better detection capability in the region FPR < 10−4. Regarding to YOLO v8, it shows a slightly higher TPR than YOLO v5 for FPR > 10−7. By considering the same confidence level, we figure out that YOLO v8 detects more targets than the version 5, but at the expense of an increased number of false positives. Such a difference between the two YOLO-based methods can be explained by considering that YOLO v8 has a more complex architecture which comports a higher risk of overfitting.

[sec5.2_p4] In Figure 6, we compare the TPR of YOLOs by varying the confidence level (i.e. the threshold) and separating the analysis in function of target dimensions. Overall, YOLO v8 has higher TPR at the same target size and confidence level, but at the price of a higher FPR, as already outlined in Figure 4.

[Figure 6: Comparison between the true positive rates of YOLO v5 (a) and YOLO v8 (b) methods by varying the confidence threshold and the target size in case of additive white Gaussian noise.]

### sec5.3 -- Results on coloured noise

[sec5.3_p1] Considering only thermal noise limits the analysis to an ideal condition which is rarely met in real situations. Other disturbances, for example, clutter, usually interfere with the returned waveform. To model this more close-to-real working condition, we tested the algorithms on maps affected by pink noise, according to the protocol described in Section 4. Because Neyman-Pearson detector is well-known to be very sensitive to non-white disturbance, we focused our analysis on CFAR and YOLO methods only. The ROC curves obtained for different levels of pink noise are shown in Figure 7. As expected, the detection performance decreases as the noise climbs, except for the CA CFAR 1D, which shows a substantial robustness by keeping its performance constant (the maximum drop is around 5% points at PFA = 10−8). This is an expected outcome because the threshold of the CFAR 1D method is proportional to the estimate of the local average noise power, which is independently estimated for each Doppler frequency. From this perspective, the non-whiteness of the noise does not increase the false detection rate. Concerning CA CFAR 2D, the dot red line highlights that the curve is just an effect of the interpolation: in truth, CA CFAR 2D produces a FPR ≅ 10−3 independently by the value of PFA. This is due to a considerable number of false detections at zero-Doppler, as shown in Figure 8. Those false detections are due to the inaccurate estimate of the mean local power within the square ring of reference cells which surround the CUT and the guard cells. Also, YOLO methods have decreasing performance, although YOLO v5 performs better than the other approaches when FPR < 10−5. CFAR approaches still guarantees a TPR higher than 0.9, but at the expense of a high FPR (greater than 10−4). By comparing the YOLOs, version 5 appears more robust than the version 8.

[Figure 7: ROC curves in presence of pink noise at 10 dB (a), 20 dB (b) and 30 dB (c). Note that the dotted red line in the plots (b) and (c) highlights that CA CFAR 2D is not able to provide a FPR less than 10−3, although the theorical PFA is less than 10−8.]

[Figure 8: Examples of target detections for CA CFAR 1D (a), CA CFAR 2D (b), YOLO v5 (c) and YOLO v8 (d). The colour bar for (a) and (b) outline the number of targets detected in the range-Doppler map, while for (c) and (d) we show the original range-Doppler map (the same for each column) with overimpressed the prediction provided by YOLO. For (a) and (b), the PFA = 10−6, and the confidence values for YOLO is 0.5.]

[sec5.3_p2] However, the advantage of machine (deep) learning is to learn from data. More specifically, YOLO-based detectors have, among other features, an enhanced capability of separating the background signal with respect to the object of interest. This characteristic is obtained through the modelling of a multi-scale spatial morphology (i.e. convolutional filters) of the signals and the definition of object-ness score dependent loss used in training. In this view, we did a last experiment by re-training the YOLO v5 with maps affected by pink noise. Similarly to what we did for the white noise case, we added to the train set a 10% of range-Doppler maps without target but with just noise to let the network learn the spatial features of the background noise. As shown in Figure 7, training the system with pink disturbances increases the detection performance. Interestingly, the best upgrade is obtained for the worst case with a pink noise of 30 dB (green lines in the figure). At the same time, it is worth noting that although the YOLO-based detector performs better after the retraining, there is still a performance loss which is proportional to the intensity of the coloured noise (see in Figure 7 the coloured dot lines with star markers). This behaviour is due to the coloured noise which overwhelms the target, especially when the target is close to zero-Doppler.

---

## sec6 -- Conclusion

[sec6_p1] Space Situational Awareness is getting an increasing attention because of the never-ending growth of the number of SO in Earth's orbits. Therefore, it is crucial to be aware of the space situation and to develop new algorithms for the defence of space infrastructures such as satellite constellations. In this context, this paper proposed a feasibility study about the adoption of DL techniques for small debris detection in monostatic pulse-Doppler radar and radio-telescopes. We modelled the European TIRA radio-telescope in tracking mode to produce training and testing data. Then, we compared classical detection systems with the novel YOLO-based detector. The evaluation in a simulated environment demonstrated that YOLO-based detection outperforms classical approach by guaranteeing high detection rate, while keeping low false alarm rates. In the future, the research activity will focus on the application of DL frameworks in other type of radar and radio telescope, as well as the integration of new methodologies for improving space operation safety and awareness.
