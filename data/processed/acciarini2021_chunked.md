# acciarini2021 -- Kessler: A Machine Learning Library for Spacecraft Collision Avoidance

**Authors:** Giacomo Acciarini, Francesco Pinto, Francesca Letizia, José A. Martinez-Heras, Klaus Merz, Christopher Bridges, Atılım Güneş Baydin
**Venue:** 8th European Conference on Space Debris (2021)
**URL:** https://conference.sdo.esoc.esa.int/proceedings/sdc8/paper/226

---

## sec0 -- Abstract

[sec0_p1] As megaconstellations are launched and the space sector grows, space debris pollution is posing an increasing threat to operational spacecraft. Low Earth orbit is a junkyard of dead satellites, rocket bodies, shrapnels, and other debris that travel at very high speed in an uncontrolled manner. Collisions at orbital speeds can generate fragments and potentially trigger a cascade of more collisions endangering the whole population, a scenario known since the late 1970s as the Kessler syndrome.

[sec0_p2] In this work we present Kessler: an open-source Python package for machine learning (ML) applied to collision avoidance. Kessler provides functionalities to import and export conjunction data messages (CDMs) in their standard format and predict the evolution of conjunction events based on explainable ML models.

[sec0_p3] In Kessler we provide Bayesian recurrent neural networks that can be trained with existing collections of CDM data and then deployed in order to predict the contents of future CDMs in a given conjunction event, conditioned on all CDMs received up to now, with associated uncertainty estimates about all predictions.

[sec0_p4] Furthermore Kessler includes a novel generative model of conjunction events and CDM sequences implemented using probabilistic programming, simulating the CDM generation process of the Combined Space Operations Center (CSpOC). The model allows Bayesian inference and also the generation of large datasets of realistic synthetic CDMs that we believe will be pivotal to enable further ML approaches given the sensitive nature and public unavailability of real CDM data.

---

## sec1 -- Introduction

[sec1_p1] With the advent of the New Space era and the launch of megaconstellations the population of human-made objects in orbit is constantly growing, together with the risk of collisions among objects. Currently, more than 30,000 objects are known to be orbiting the Earth, including a small percentage of payloads of active missions, and a vast population of rocket bodies, mission related objects, debris, and inactive satellites. Several studies exist that analyze the future growth of space objects and warn about the associated increase in collision risks [30, 29, 38, 34].

[sec1_p2] In 1978, Donald J. Kessler and Burton Cour-Palais, scientists at the NASA Johnson Space Center, conjectured a theoretical scenario where where a few collisions could produce orbiting fragments that would in turn increase the probability of further collisions and potentially trigger a chain reaction leading to the growth of a debris belt around the Earth [22], a process that has been known as the Kessler syndrome since the 1980s. As past collision events demonstrated [4], a collision among satellites can release thousands of debris pieces, which travel at extremely high velocities, therefore representing a big threat for the neighboring population of resident space objects.

[sec1_p3] For these reasons, international institutions and space agencies constantly release and update international guidelines for the mitigation of collision risk and the safeguarding of the space environment [9]. Moreover, satellite operators continuously monitor operational satellites and perform collision avoidance actions (e.g., maneuvers) for reducing the collision risk. The US Strategic Command (USSTRATCOM) continuously tracks resident space objects via a global Space Surveillance Network (SSN) and updates a public catalog of two-line element (TLE) data, where each epoch some environment model parameters are stored together with orbital element information from which the current position and velocity of resident space objects can be estimated.

[sec1_p4] Meanwhile, the Combined Space Operations Center (CSpOC) propagates the SSN observations several days into the future, and monitors possible collision events with other objects in space. If a conjunction has been projected according to some screening criteria, then a "Conjunction Data Message" (CDM) [12] is released to the owner/operator of the satellite. This message contains information about the conjunction event at the predicted time of closest approach (TCA), such as environment aspects used for the orbit propagation, as well as the predicted states of the screened pair of objects, and their associated uncertainties (in the form of covariances). Furthermore, as more observations are processed by CSpOC, new CDMs are released in the week leading up to TCA. Usually, operators are provided with a time-series of CDMs that they use for analyzing each conjunction event and for planning risk mitigation strategies when needed [8, 33, 11].

[sec1_p5] The tasks of assessing the collision risk of a conjunction event and devising an optimal strategy to mitigate collision risk place a significant burden on space operators that is expected to increase as more objects are launched in space and the space sector grows [28]. Several ways of tackling the space debris problem have been studied by companies, space agencies and researchers in the last years [25, 46, 31, 24]. Recently, the European Space Agency (ESA) has started an international competition called the Collision Avoidance Challenge to study the possibility of helping human operators through machine learning (ML) based approaches that can model and predict conjunction events, therefore alleviating the burden on operators [42].

[sec1_p6] During the competition, a dataset of thousands of CDMs collected by ESA from 2015 to 2019 has been released, which we call the Kelvins dataset [41]. Although this represents the first public release of CDMs, the data were partially anonymized, hiding the full state (position and velocity) of the satellites, as well as any absolute time information (e.g., TCA, CDM creation time) and other information (e.g., objects' identities).

[sec1_p7] We believe that ML approaches will be essential in improving collision avoidance analyses and decision making processes in the near future and enable scalable automated systems that would greatly enhance the collision avoidance process, with positive consequences for the safeguarding of the space environment. Following up on the ESA studies, we develop Kessler (Figure 1) a ML library for spacecraft collision avoidance, that we named in honor of the NASA scientist Donald J. Kessler known for proposing the Kessler syndrome. To deliver maximum benefit to the space and ML communities, we release Kessler as an open-source project that we expect to keep improving following this initial release and to which we welcome contributions from the wider community.

[sec1_p8] Kessler is an open-source Python package that currently includes Bayesian ML and probabilistic programming components. The library currently provides the following key capabilities: functionality to import and export CDM data, using either the CDM standard format or databases that can be connected to Kessler through an API based on pandas DataFrame objects, and grouping CDMs into Event objects representing conjunctions; plotting code to visualize event evolution either in a sequence of existing CDMs in a conjunction event, or with future CDMs predicted by the ML modules, representing event evolution predictions with associated uncertainty information; a ML module that currently implements Bayesian recurrent neural networks, specifically based on a stack of the long short-term memory (LSTM) architecture [18] that we designed and evaluated to work well in this setting [37], ready to train with the user's own collection of CDM data; and a probabilistic programming module simulating conjunction events and CDM generation processes, which can be used for either performing event analysis using Bayesian inference or generation of synthetic CDM datasets sampled from this probabilistic generative model.

[sec1_p9] In the following, we will describe the package and its key features. In particular, we will first discuss related work and methodology on which the main Kessler tools are based on. Then we will detail the software architecture, show some of the package functionalities, and present our conclusions and recommendations for future work.

---

## sec2 -- Related Work

### sec2.1 -- Spacecraft collision avoidance

[sec2.1_p1] As previously discussed, operators regularly receive CDM updates describing target and chaser objects in a conjunction event and their associated uncertainties, in the week leading up to TCA. Optionally, the data is augmented with other sources (e.g., other radar measurements, telemetry).

[sec2.1_p2] Given this collection of information, operators usually perform two steps. First, in case more data are available, they combine the information and assess the state of the two objects and their uncertainties at TCA, for which several techniques exist and are used. These range from linear/linearised methods such as Kalman filters [43], to semi-analytic techniques such as differential algebra with Gaussian mixture models, and polynomial chaos expansion [39, 20, 45, 2], or sampling-based techniques such as Monte Carlo [13]. Second, they process the CDM information and their own analysis (if relevant) to obtain collision risk estimates for the studied conjunction event. Usually the more the time approaches TCA, the more CDMs contain precise (i.e., less uncertain) information. Therefore, in a typical scenario, the operators continuously update these risk estimates, until one or two days before TCA, where they shall make a decision on whether to maneuver the craft or not in order to avoid a collision.

### sec2.2 -- Bayesian machine learning

[sec2.2_p1] Although ML, mainly in the form of deep learning [15, 27], has been extremely successful in providing state-of-the-art results in many complex applications, it is well known that the predictions of neural networks can be over-confident even when the network produces a wrong prediction [3, 26, 40]. This problem is one of the main factors to consider in the application of neural networks to safety-critical applications. To address this issue, ML research has delivered several techniques to augment neural networks with reliable uncertainty measures that should clearly indicate when the model is confident in its predictions or not. Some of these techniques are ascribed to the family of Bayesian deep learning models [47, 21, 7], where the idea is to design models that can produce probability distributions as outputs (as opposed to single point estimates), and to measure the uncertainty on a prediction as a spread over such distributions (e.g., variance or entropy). This can be achieved by replacing the weights of a neural network with probability distributions over these weights, learned via an inference procedure at training time. Since applying inference is usually computationally expensive, many approximate inference schemes have been designed.

[sec2.2_p2] One of the most popular approximate inference schemes is Monte Carlo dropout, where the idea is to apply dropout, originally proposed as a regularization scheme for neural network training [17], both at training and test time [14]. Dropout is a technique that randomly switches off a proportion of the units of a neural network by sampling a binary mask according to a Bernoulli distribution. It has been shown that, if applied at test time, this technique can be considered a variational approximate inference scheme. For this reason, the distribution produced by feeding the same input to the neural network multiple times with dropout (i.e., resampling the mask that switches off different units in each evaluation) can be used to quantify the uncertainty of the trained neural network.

### sec2.3 -- Probabilistic programming

[sec2.3_p1_1] Probabilistic programming [16, 44] is a paradigm for statistical modeling that enables automated Bayesian inference in probabilistic models implemented using general-purpose programming languages. It is a technique that can be classified under the larger field of simulation-based inference [10]. Recently techniques have been developed to enable the use of existing stochastic simulator code bases as probabilistic programs so that Bayesian inference in these simulators can be performed [5, 6], creating a new connection between a very large collection of accurate large-scale simulators in many application domains and probabilistic inference techniques developed by the ML community.

[sec2.3_p1_2] The idea in probabilistic programming is to leverage domain knowledge to design a simulator (a model) that accurately reproduces the phenomenon of interest. The simulator includes a collection of latent random variables x, each of which is assumed to be distributed according to a prior distribution in a Bayesian setting, jointly referred to as p(x), expressing the domain knowledge. The joint prior distribution encodes the expert's knowledge about the values that x can assume in the given application and the belief about their probability of occurrence before observing the data point on which inference needs to be performed. In addition to the latent variables x, the model includes observable random variables y. Given the priors p(x) and the generative model that produces y from x, the simulator implicitly specifies a joint distribution p(x, y) = p(x) p(y|x). Using an observation model defined through the specification of the likelihood p(y|x), families of inference algorithms (e.g., Markov chain Monte Carlo, importance sampling, variational inference) allow to automatically produce posterior distributions p(x|y), which describe values of x that could have generated the observed data y, therefore explaining the observed data under the model specified by the probabilistic program. Crucially, the joint generative model p(x, y) can also be used to generate synthetic data instances sampled from the generative model.

---

## sec3 -- Methodology

### sec3.1 -- Bayesian ML for spacecraft conjunctions

[sec3.1_p1] In previous work [37] we discuss that approaching the spacecraft collision avoidance problem as discriminative binary-classification formulation in ML (i.e., high- vs low-risk events) has various shortcomings (e.g., training data class imbalance, scarce interpretability of the output). For this reason, we focus our attention on the generative modeling of the problem, in other words we would like to deliver ML methods that describe the temporal evolution of a sequence of CDMs given all previously observed CDMs.

[sec3.1_p2] More specifically, we train a special kind of recurrent neural network, a long short-term memory (LSTM) network [18] to predict the features and time of arrival of the next CDM given all previous CDMs in an evolving conjunction event (Figure 2). This setup is analogous to statistical language models in ML [32, 23] that predict the probability of the next symbol (e.g., a character or a whole word) in a given language, conditioned on all the symbols seen up to a given point. In order to quantify the uncertainty about the predicted values, we set up this network as a Bayesian neural network and apply Monte Carlo dropout at test time.

[Figure 2: At training time the LSTM is optimized to reproduce the time-shifted CDM sequences in training data. At test time, given a sequence of CDMs for the current event, the trained LSTM is used to predict future CDMs that characterise the event evolution.]

### sec3.2 -- A generative probabilistic model for spacecraft orbits, collisions, and CDM generation

[sec3.2_p1] As mentioned previously and discussed in previous work [1], a pivotal component of the probabilistic programming approach is the definition and construction of a stochastic generative model. In this case, the purpose of the model is not only to mimic conjunction events, but also to simulate the CDM generation process. Once such a model is calibrated, it can then be used for either data generation or inference purposes.

[sec3.2_p2] Here we briefly detail the construction of such a model and its key elements. The first essential component of the model are the priors: these are probability density functions describing the current resident space objects characteristics (e.g., mass, area) and orbits (e.g., orbital elements). We constructed these distributions based on real data collected from the public USSTRATCOM catalog and ESA DISCOS database. By sampling from these distributions, two objects (i.e., the target and the chaser) are instantiated, and their initial two-line elements (TLEs) are extracted [35]. Once this is done, the orbits of the objects are propagated forward in time using an orbital propagator to produce ground-truth orbit trajectories. We used SGP4 propagator for preliminary experiments and design of the software, a fast low-precision propagator often used for preliminary analysis of orbital trajectories in low Earth orbit [19]. Having propagated the orbits, a check is made if a conjunction warning is to be triggered. If that is the case, we flag the event as a conjunction event and we simulate the ground observation part, by generating radar measurements, propagating them until TCA via Monte Carlo propagation, and generating CDMs associated with each observation. Both the timing of these observations and the measurement errors have been calibrated on the Kelvins dataset. In particular, the observation times have been formulated as probability distributions and have been calibrated to match Kelvins dataset distributions, whereas measurement errors were calibrated by tuning their values until the propagated covariance distributions at TCA were matching the ones in the Kelvins dataset.

---

## sec4 -- Software Architecture

[sec4_p1] Kessler is written in Python 3 and made available through a GitHub repository. Kessler software architecture consists of several components. The first one covers the importing, exporting, plotting and analysis functionalities, where CDMs can be loaded and analyzed both graphically and statistically. Then, two other main functionalities are present: a ML module where Bayesian LSTMs can be trained using a dataset of existing CDMs and subsequently used to make predictions of future CDMs in new conjunction events at test time; and a probabilistic programming module that provides a generative model for conjunction events and CDMs. In this section, we will briefly detail these Kessler functionalities and discuss their usage.

### sec4.1 -- CDM importing and exporting, analysis, and visualization

[sec4.1_p1] Kessler offers two main possibilities to load CDMs: either from their original kvn format, or from a pandas DataFrame object. Once loaded, CDMs are divided into conjunction events automatically and their units fulfill the CDM standard format [12]. Then, the software offers two main functionalities to plot the conjunction events (i.e., time series of CDMs): plot_features(), a function that takes as input the features to be visualized of the conjunction event(s) and plots them (an example for three events is shown in Figure 3); and plot_uncertainties(), a function that plots all the covariance matrix elements for the considered events and for both the objects (an example of its usage is shown in Figure 4). Moreover, the CDM content can also be manually inspected and processed by accessing the relevant CDMs from the event dataset object.

[Figure 3: An example of plot_features() usage, for three events and with three different features plotted: relative speed, miss distance and along-track component of relative velocity.]

[Figure 4: An example of plot_uncertainties() usage, for three events.]

### sec4.2 -- Machine learning module

[sec4.2_p1] Besides loading and plotting functionalities, the library also offers a ML module, where a Bayesian LSTM can be instantiated as an LSTMPredictor object and trained on datasets of CDMs. The ML implementations in Kessler are based on PyTorch [36]. The learn function can be called by passing the relevant neural network training hyperparameters (e.g., batch size, learning rate).

[sec4.2_p2] Once the model is learned from data, it can be used to predict future CDMs in new, previously unseen, conjunction events at test time. Kessler offers two different functions for doing this: model.predict_event_step() and model.predict_event(). While the former only predicts the next CDM, the latter predicts the entire CDM sequence, using the neural network's predicted CDM at each time step as an input for future time steps (Figure 2). Due to the Bayesian nature of the implemented stacked LSTM architecture, the network returns distributions rather than point predictions. In Figure 5, we show an example of both functions' usage.

[Figure 5: Top row: usage of model.predict_event(), where the first CDM is used for predicting the whole event. Bottom row: usage of model.predict_event_step(), where the next CDM is predicted from a time series of CDMs.]

### sec4.3 -- Probabilistic programming module

[sec4.3_p1] A key novelty of the Kessler package is its probabilistic programming module, which uses PyProb [6], a universal probabilistic-programming framework based on PyTorch. This module can be used to generate synthetic conjunction events by simply importing the Conjunction object from Kessler, and by either sampling event realizations from the prior model and filtering the forward samples for only events that represent conjunctions or by generating each conjunction individually. This can be done by using two separate functions: prior = model.prior(N), which samples the prior N times, therefore producing N ground truth orbits of target and chaser pairs (these events can then be filtered using model.filter() for only those that are conjunction events and thus contain associated synthetic CDMs); and model.get_conjunction(), which automatically samples the prior distributions until a conjunction event is found, and returns the conjunction event, whose CDMs and features can then be analyzed, plotted and/or predicted.

[Figure 6: Several features of the sampled priors, including the distributions of the orbital elements of both target and chaser and the orbit geometry and some key CDMs features of one of the sampled conjunction events. Conjunction events are highlighted in orange and non-conjunction ones in blue.]

[sec4.3_p2] As already discussed, this generative model can be used in PyProb probabilistic programming framework to perform posterior inference over model latents using posterior = model.posterior(N, observation), conditioned on observed CDMs. For this, one has to choose the inference engine (e.g., importance sampling, Markov chain Monte Carlo) and the likelihood distributions that describe the probability of the observed data conditioned on the latents. In previous work [1], some experiments with these techniques have been presented and discussed.

---

## sec5 -- Conclusions

[sec5_p1] In this work we introduced Kessler, a new open-source project focused on delivering high-quality and tested ML techniques to the space community for applications in spacecraft collision avoidance. We would like to maintain and develop Kessler further as a state-of-the-art ML library with contributions from the larger ML and space communities. The community can leverage Kessler for several different purposes, and here we finish by listing some of its key use cases: importing, analyzing, and visualizing CDM sequences; training of ML models from private or public datasets of real CDMs in order to deploy these models to perform predictions at test time with new conjunction events with associated model uncertainties; simulating conjunction events and generating realistic synthetic CDM datasets, which can be used as training data to enable further ML approaches; performing Bayesian inference and therefore helping operators/users to determine key variables that lead to conjunction events and make reliable predictions (with associated uncertainties); and providing an open-source framework to host future risk assessment approaches based on ML and Bayesian inference.

[Acknowledgments omitted: funding boilerplate]
